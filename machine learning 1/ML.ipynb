{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbc0d1c-883a-405e-906c-e3c8b50c9c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_test = [(5, -3), (-3, 8), (3, 6), (0, 0), (5, 3), (-3, -1), (-3, 3)]\n",
    "\n",
    "w=[-33,9,13]\n",
    "fun=lambda x: np.sign(x[0]*w[1]+x[1]*w[2]+w[0])\n",
    "predict=[fun(x_test[i]) for i in range(len(x_test))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafcf325-b50e-47ca-82f6-ed350036d2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_test = [(9, 6), (2, 4), (-3, -1), (3, -2), (-3, 6), (7, -3), (6, 2)]\n",
    "\n",
    "w=[14,-7,5]\n",
    "fun=lambda x: np.sign(x[0]*w[1]+x[1]*w[2]+w[0])\n",
    "predict=[fun(x_test[i]) for i in range(len(x_test))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3ce941-0acc-4d22-bfc7-c4299ee888fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "w = np.array([15/7, -9/7, -1])\n",
    "x_test = np.array([[-8,-4],[-2,2],[4,8],[6,3]]) # задайте самостоятельно (признаки образов: x0, x1, x2)\n",
    "y_test = np.array([1,1,-1,-1]) # задайте самостоятельно (метки класса)\n",
    "\n",
    "# здесь продолжайте программу\n",
    "fun=lambda x: x[0]*w[1]+x[1]*w[2]+w[0]\n",
    "margin=[fun(x_test[i])*y_test[i] for i in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fc7e71-97cd-4723-90d1-b07459b0ca10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "w = np.array([-16,-4,9]) # задайте самостоятельно (параметры модели: w0, w1, w2 - ориентация разделяющей линии)\n",
    "x_test = np.array([[-5,2],[-4,6],[3,2],[3,-3],[5,6],[9,2]]) # задайте самостоятельно (признаки образов: x0, x1, x2)\n",
    "y_test = np.array([1,1,1,-1,-1,-1]) # задайте самостоятельно (метки класса)\n",
    "\n",
    "# здесь продолжайте программу\n",
    "a_model=lambda x: x[0]*w[1]+x[1]*w[2]+w[0]\n",
    "margin=[a_model(x_test[i])*y_test[i] for i in range(6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc43951-886f-4d80-a38e-fa45e408c4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_test = np.array([(-5, 2), (-4, 6), (3, 2), (3, -3), (5, 5), (5, 2), (-1, 3)])\n",
    "y_test = np.array([1, 1, 1, -1, -1, -1, -1])\n",
    "w = np.array([-8, -2, 3])\n",
    "\n",
    "# здесь продолжайте программу\n",
    "a_model=lambda x: np.sign(x[0]*w[1]+x[1]*w[2]+w[0])\n",
    "margin=np.array([a_model(x_test[i])*y_test[i] for i in range(7)])\n",
    "print(np.sum(margin[margin<0])*(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12084b8-32c3-41ea-a69b-8ff8e2223c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def func(x):\n",
    "    return 0.1 * x**2 - np.sin(x) + 0.1 * np.cos(x * 5) + 1.\n",
    "\n",
    "\n",
    "# здесь объявляйте дополнительные функции (если необходимо)\n",
    "\n",
    "\n",
    "coord_x = np.arange(-5.0, 5.0, 0.1) # значения отсчетов по оси абсцисс\n",
    "coord_y = func(coord_x) # значения функции по оси ординат\n",
    "w=[1.11, -0.26, 0.061, 0.0226, 0.00178]\n",
    "\n",
    "sz = len(coord_x) # общее число отсчетов\n",
    "\n",
    "# здесь продолжайте программу\n",
    "a_model= lambda x: w[0]+x*w[1]+(x**2)*w[2]+(x**3)*w[3]+(x**4)*w[4]\n",
    "L_model= lambda x,y: (a_model(x)-y)**2\n",
    "Q=(1/sz)*sum(L_model(coord_x[i],coord_y[i]) for i in range(sz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab42e9d-2997-454a-ad64-1a6faaa8c511",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def func(x):\n",
    "    return 0.5 * x**2 - 0.1 * 1/np.exp(-x) + 0.5 * np.cos(2*x) - 2.\n",
    "\n",
    "\n",
    "# здесь объявляйте дополнительные функции (если необходимо)\n",
    "\n",
    "\n",
    "coord_x = np.arange(-5.0, 5.0, 0.1) # значения отсчетов по оси абсцисс\n",
    "coord_y = func(coord_x) # значения функции по оси ординат\n",
    "w=[-1.59,-0.69,0.278,0.497,-0.106]\n",
    "\n",
    "sz = len(coord_x) # общее число отсчетов\n",
    "# здесь продолжайте программу\n",
    "a_model=lambda x: w[0]+x*w[1]+x**2*w[2]+np.cos(2*x)*w[3]+np.sin(2*x)*w[4]\n",
    "L_model= lambda x,y: np.abs(a_model(x)-y)\n",
    "Q=(1/sz)*sum(L_model(coord_x,coord_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd12b3c-98ec-492d-8b56-0ad68dbdc792",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_x = np.array([(5.8, 1.2), (5.6, 1.5), (6.5, 1.5), (6.1, 1.3), (6.4, 1.3), (7.7, 2.0), (6.0, 1.8), (5.6, 1.3), (6.0, 1.6), (5.8, 1.9), (5.7, 2.0), (6.3, 1.5), (6.2, 1.8), (7.7, 2.3), (5.8, 1.2), (6.3, 1.8), (6.0, 1.0), (6.2, 1.3), (5.7, 1.3), (6.3, 1.9), (6.7, 2.5), (5.5, 1.2), (4.9, 1.0), (6.1, 1.4), (6.0, 1.6), (7.2, 2.5), (7.3, 1.8), (6.6, 1.4), (5.6, 2.0), (5.5, 1.0), (6.4, 2.2), (5.6, 1.3), (6.6, 1.3), (6.9, 2.1), (6.8, 2.1), (5.7, 1.3), (7.0, 1.4), (6.1, 1.4), (6.1, 1.8), (6.7, 1.7), (6.0, 1.5), (6.5, 1.8), (6.4, 1.5), (6.9, 1.5), (5.6, 1.3), (6.7, 1.4), (5.8, 1.9), (6.3, 1.3), (6.7, 2.1), (6.2, 2.3), (6.3, 2.4), (6.7, 1.8), (6.4, 2.3), (6.2, 1.5), (6.1, 1.4), (7.1, 2.1), (5.7, 1.0), (6.8, 1.4), (6.8, 2.3), (5.1, 1.1), (4.9, 1.7), (5.9, 1.8), (7.4, 1.9), (6.5, 2.0), (6.7, 1.5), (6.5, 2.0), (5.8, 1.0), (6.4, 2.1), (7.6, 2.1), (5.8, 2.4), (7.7, 2.2), (6.3, 1.5), (5.0, 1.0), (6.3, 1.6), (7.7, 2.3), (6.4, 1.9), (6.5, 2.2), (5.7, 1.2), (6.9, 2.3), (5.7, 1.3), (6.1, 1.2), (5.4, 1.5), (5.2, 1.4), (6.7, 2.3), (7.9, 2.0), (5.6, 1.1), (7.2, 1.8), (5.5, 1.3), (7.2, 1.6), (6.3, 2.5), (6.3, 1.8), (6.7, 2.4), (5.0, 1.0), (6.4, 1.8), (6.9, 2.3), (5.5, 1.3), (5.5, 1.1), (5.9, 1.5), (6.0, 1.5), (5.9, 1.8)])\n",
    "data_y = np.array([-1, -1, -1, -1, -1, 1, 1, -1, -1, 1, 1, -1, 1, 1, -1, 1, -1, -1, -1, 1, 1, -1, -1, -1, -1, 1, 1, -1, 1, -1, 1, -1, -1, 1, 1, -1, -1, 1, 1, -1, 1, 1, -1, -1, -1, -1, 1, -1, 1, 1, 1, 1, 1, -1, -1, 1, -1, -1, 1, -1, 1, -1, 1, 1, -1, 1, -1, 1, 1, 1, 1, 1, -1, -1, 1, 1, 1, -1, 1, -1, -1, -1, -1, 1, 1, -1, 1, -1, 1, 1, 1, 1, -1, 1, 1, -1, -1, -1, -1, 1])\n",
    "\n",
    "data_xc1=np.array(data_x[data_y>0])\n",
    "data_xc2=np.array(data_x[data_y<0])\n",
    "sz=len(data_x)\n",
    "dtx=np.array([(1, data_x[i][0], data_x[i][1]) for i in range(sz)])\n",
    "\n",
    "sum1=sum(dtx[i]*data_y[i] for i in range(sz))\n",
    "sum2 = np.sum([np.outer(x, x) for x in dtx], axis=0)\n",
    "w=np.dot(sum1, np.linalg.inv(sum2))\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(data_xc1[:,0], data_xc1[:,1], c=\"r\")\n",
    "plt.scatter(data_xc2[:,0], data_xc2[:,1], c=\"b\")\n",
    "plt.axline((5,-5*w[1]/w[2]-w[0]/w[2]),(4,-4*(w[1]/w[2])-w[0]/w[2]))\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff003df-9ea1-4840-87c3-d5244a6bc574",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def func(x):\n",
    "    return 0.5 * x + 0.2 * x ** 2 - 0.1 * x ** 3\n",
    "\n",
    "\n",
    "def df(x):\n",
    "    return 0.5+0.4*x-0.3*x**2\n",
    "\n",
    "coord_x = np.arange(-5.0, 5.0, 0.1) # значения по оси абсцисс\n",
    "coord_y = func(coord_x) # значения по оси ординат (значения функции)\n",
    "\n",
    "x=-4\n",
    "n=0.01\n",
    "for i in range(200):\n",
    "    x-=df(x)*n\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf03c6e1-e93b-4b5a-ab1c-f66215e1cf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# исходная функция, которую нужно аппроксимировать моделью a(x)\n",
    "def func(x):\n",
    "    return 0.1 * x**2 - np.sin(x) + 5.\n",
    "def s(x):\n",
    "    return np.array([1, x, x**2, x**3])\n",
    "\n",
    "\n",
    "# здесь объявляйте необходимые функции\n",
    "\n",
    "coord_x = np.arange(-5.0, 5.0, 0.1) # значения по оси абсцисс [-5; 5] с шагом 0.1\n",
    "coord_y = func(coord_x) # значения функции по оси ординат\n",
    "\n",
    "sz = len(coord_x)\t# количество значений функций (точек)\n",
    "eta = np.array([0.1, 0.01, 0.001, 0.0001]) # шаг обучения для каждого параметра w0, w1, w2, w3\n",
    "w = np.array([0., 0., 0., 0.]) # начальные значения параметров модели\n",
    "N = 200 # число итераций градиентного алгоритма\n",
    "for i in range(N):\n",
    "    dQ=sum((np.dot(w,s(coord_x[i]).T)-func(coord_x[i]))*s(coord_x[i]) for i in range(sz))*(2/sz)\n",
    "    w=w-eta*dQ\n",
    "a_model=lambda x: w[0]+w[1]*x+w[2]*x**2+w[3]*x**3\n",
    "Q=(1/sz)*np.sum((a_model(coord_x)-func(coord_x))**2)\n",
    "print(Q,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64846f54-cdde-4699-afff-dfb84c5eb272",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# исходная функция, которую нужно аппроксимировать моделью a(x)\n",
    "def func(x):\n",
    "    return 0.5 * x**2 - 0.1 * 1/np.exp(-x) + 0.5 * np.cos(2*x) - 2.\n",
    "\n",
    "\n",
    "# здесь объявляйте необходимые функции\n",
    "a_model = lambda x: w[0] + w[1]*x + w[2]*x**2 + w[3]*np.cos(2*x) + w[4]*np.sin(2*x)\n",
    "def x(x):\n",
    "    return np.array([1, x ,x**2, np.cos(2*x), np.sin(2*x)])\n",
    "\n",
    "coord_x = np.arange(-5.0, 5.0, 0.1) # значения по оси абсцисс [-5; 5] с шагом 0.1\n",
    "coord_y = func(coord_x) # значения функции по оси ординат\n",
    "\n",
    "sz = len(coord_x)\t# количество значений функций (точек)\n",
    "eta = np.array([0.01, 0.001, 0.0001, 0.01, 0.01]) # шаг обучения для каждого параметра w0, w1, w2, w3, w4\n",
    "w = np.array([0., 0., 0., 0., 0.]) # начальные значения параметров модели\n",
    "N = 500 # число итераций алгоритма SGD\n",
    "lm = 0.02 # значение параметра лямбда для вычисления скользящего экспоненциального среднего\n",
    "\n",
    "Qe = (1/sz)*np.sum((a_model(coord_x)-coord_y)**2)\n",
    "\n",
    "np.random.seed(0) # генерация одинаковых последовательностей псевдослучайных чисел\n",
    "\n",
    "for i in range(500):\n",
    "    k=np.random.randint(0,sz-1)\n",
    "    xx=x(coord_x[k])\n",
    "    L=(np.dot(w,xx.T)-coord_y[k])**2\n",
    "    dL=np.dot(2*(np.dot(w,xx.T)-coord_y[k]),xx)\n",
    "    w=w-eta*dL\n",
    "    Qe=lm*L+(1-lm)*Qe\n",
    "Q=(1/sz)*sum((np.dot(w,x(coord_x[k]))-coord_y[k])**2 for k in range(sz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8871ea2-47f3-47b3-bb15-c114578e205c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# исходная функция, которую нужно аппроксимировать моделью a(x)\n",
    "def func(x):\n",
    "    return 0.5 * x + 0.2 * x ** 2 - 0.05 * x ** 3 + 0.2 * np.sin(4 * x) - 2.5\n",
    "\n",
    "\n",
    "# здесь объявляйте необходимые функции\n",
    "a_model = lambda x: w[0]+w[1]*x+w[2]*x**2+w[3]*x**3\n",
    "def x(x):\n",
    "    return np.array([1, x, x**2, x**3])\n",
    "\n",
    "coord_x = np.arange(-4.0, 6.0, 0.1) # значения по оси абсцисс [-4; 6] с шагом 0.1\n",
    "coord_y = func(coord_x) # значения функции по оси ординат\n",
    "\n",
    "sz = len(coord_x)\t# количество значений функций (точек)\n",
    "eta = np.array([0.1, 0.01, 0.001, 0.0001]) # шаг обучения для каждого параметра w0, w1, w2, w3\n",
    "w = np.array([0., 0., 0., 0.]) # начальные значения параметров модели\n",
    "N = 500 # число итераций алгоритма SGD\n",
    "lm = 0.02 # значение параметра лямбда для вычисления скользящего экспоненциального среднего\n",
    "batch_size = 50 # размер мини-батча (величина K = 50)\n",
    "\n",
    "Qe = (1/sz)*np.sum((a_model(coord_x)-coord_y)**2)\n",
    "np.random.seed(0) # генерация одинаковых последовательностей псевдослучайных чисел\n",
    "for i in range(N):\n",
    "    k=np.random.randint(0,sz-1-batch_size)\n",
    "    L=(1/batch_size)*sum((np.dot(w, x(coord_x[i]).T)-coord_y[i])**2 for i in range(k, k+batch_size))\n",
    "    Qe=lm*L+(1-lm)*Qe\n",
    "    dL=(2/batch_size)*sum(np.dot(np.dot(w,x(coord_x[i]))-coord_y[i],x(coord_x[i]).T) for i in range(k, k+batch_size))\n",
    "    w=w-eta*dL\n",
    "Q=(1/sz)*sum((np.dot(w, x(coord_x[i]))-coord_y[i])**2 for i in range(sz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9124376-00bd-4949-94cb-81409bc07fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# логарифмическая функция потерь\n",
    "def loss(w, x, y):\n",
    "    M = np.dot(w, x) * y\n",
    "    return np.log2(1 + np.exp(-M))\n",
    "\n",
    "\n",
    "# производная логарифмической функции потерь по вектору w\n",
    "def df(w, x, y):\n",
    "    M = np.dot(w, x) * y\n",
    "    return -(np.exp(-M) * x.T * y) / ((1 + np.exp(-M)) * np.log(2))\n",
    "a_model= lambda x, y: np.dot(w, x.T)*y \n",
    "    \n",
    "\n",
    "data_x = np.array([(3.0, 4.9), (2.7, 3.9), (3.0, 5.5), (2.6, 4.0), (2.9, 4.3), (3.1, 5.1), (2.2, 4.5), (2.3, 3.3), (2.7, 5.1), (3.3, 5.7), (2.8, 5.1), (2.8, 4.9), (2.5, 4.5), (2.8, 4.7), (3.2, 4.7), (3.2, 5.7), (2.8, 6.1), (3.6, 6.1), (2.8, 4.8), (2.9, 4.5), (3.1, 4.9), (2.3, 4.4), (3.3, 6.0), (2.6, 5.6), (3.0, 4.4), (2.9, 4.7), (2.8, 4.0), (2.5, 5.8), (2.4, 3.3), (2.8, 6.7), (3.0, 5.1), (2.3, 4.0), (3.1, 5.5), (2.8, 4.8), (2.7, 5.1), (2.5, 4.0), (3.1, 4.4), (3.8, 6.7), (3.1, 5.6), (3.1, 4.7), (3.0, 5.8), (3.0, 5.2), (3.0, 4.5), (2.7, 4.9), (3.0, 6.6), (2.9, 4.6), (3.0, 4.6), (2.6, 3.5), (2.7, 5.1), (2.5, 5.0), (2.0, 3.5), (3.2, 5.9), (2.5, 5.0), (3.4, 5.6), (3.4, 4.5), (3.2, 5.3), (2.2, 4.0), (2.2, 5.0), (3.3, 4.7), (2.7, 4.1), (2.4, 3.7), (3.0, 4.2), (3.2, 6.0), (3.0, 4.2), (3.0, 4.5), (2.7, 4.2), (2.5, 3.0), (2.8, 4.6), (2.9, 4.2), (3.1, 5.4), (2.5, 4.9), (3.2, 5.1), (2.8, 4.5), (2.8, 5.6), (3.4, 5.4), (2.7, 3.9), (3.0, 6.1), (3.0, 5.8), (3.0, 4.1), (2.5, 3.9), (2.4, 3.8), (2.6, 4.4), (2.9, 3.6), (3.3, 5.7), (2.9, 5.6), (3.0, 5.2), (3.0, 4.8), (2.7, 5.3), (2.8, 4.1), (2.8, 5.6), (3.2, 4.5), (3.0, 5.9), (2.9, 4.3), (2.6, 6.9), (2.8, 5.1), (2.9, 6.3), (3.2, 4.8), (3.0, 5.5), (3.0, 5.0), (3.8, 6.4)])\n",
    "data_y = np.array([1, -1, 1, -1, -1, 1, -1, -1, -1, 1, 1, 1, 1, -1, -1, 1, 1, 1, -1, -1, -1, -1, 1, 1, -1, -1, -1, 1, -1, 1, 1, -1, 1, 1, 1, -1, -1, 1, 1, -1, 1, 1, -1, 1, 1, -1, -1, -1, 1, 1, -1, 1, 1, 1, -1, 1, -1, 1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, 1, -1, 1, -1, 1, 1, -1, 1, 1, -1, -1, -1, -1, -1, 1, 1, 1, 1, 1, -1, 1, -1, 1, -1, 1, 1, 1, -1, 1, -1, 1])\n",
    " \n",
    "x_train = np.array([[1, x[0], x[1]] for x in data_x])\n",
    "y_train = np.array(data_y)\n",
    "\n",
    "n_train = len(x_train)  # размер обучающей выборки\n",
    "w = [0.0, 0.0, 0.0]  # начальные весовые коэффициенты\n",
    "nt = np.array([0.5, 0.01, 0.01])   # шаг обучения для каждого параметра w0, w1, w2\n",
    "lm = 0.01  # значение параметра лямбда для вычисления скользящего экспоненциального среднего\n",
    "N = 1000  # число итераций алгоритма SGD\n",
    "\n",
    "Qe = np.sum(np.log2(1+np.exp(-np.dot(w, x_train.T)*y_train)))\n",
    "np.random.seed(0) # генерация одинаковых последовательностей псевдослучайных чисел\n",
    "\n",
    "for i in range(N):\n",
    "    k=np.random.randint(0,n_train-1)\n",
    "    L=np.log2(1+np.exp(-np.dot(w, x_train[k].T)*y_train[k]))\n",
    "    Qe=lm*L+(1-lm)*Qe\n",
    "    dL=(-np.exp(-np.dot(w, x_train[k].T)*y_train[k])*x_train[k]*y_train[k])/((1+np.exp(-np.dot(w, x_train[k].T)*y_train[k]))*np.log(2))\n",
    "    w=w-nt*dL\n",
    "margin=np.array([loss(w, x_train[i], y_train[i]) for i in range(n_train)])\n",
    "Q = (a_model(x_train, y_train)<0).mean()\n",
    "\n",
    "data_xc1=np.array(data_x[data_y>0])\n",
    "data_xc2=np.array(data_x[data_y<0])\n",
    "\n",
    "plt.grid()\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(data_xc1[:,0], data_xc1[:,1], c=\"r\")\n",
    "plt.scatter(data_xc2[:,0], data_xc2[:,1], c=\"b\")    \n",
    "plt.axline((5,-5*w[1]/w[2]-w[0]/w[2]),(4,-4*(w[1]/w[2])-w[0]/w[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d000a1-6a72-42ae-b6aa-5fd278266f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# экспоненциальная функция потерь\n",
    "def loss(w, x, y):\n",
    "    M = np.dot(w, x) * y\n",
    "    return np.exp(-M)\n",
    "\n",
    "\n",
    "# производная экспоненциальной функции потерь по вектору w\n",
    "def df(w, x, y):\n",
    "    M = np.dot(w, x) * y\n",
    "    return -np.exp(-M) * x.T * y\n",
    "\n",
    "\n",
    "data_x = np.array([(5.8, 1.2), (5.6, 1.5), (6.5, 1.5), (6.1, 1.3), (6.4, 1.3), (7.7, 2.0), (6.0, 1.8), (5.6, 1.3), (6.0, 1.6), (5.8, 1.9), (5.7, 2.0), (6.3, 1.5), (6.2, 1.8), (7.7, 2.3), (5.8, 1.2), (6.3, 1.8), (6.0, 1.0), (6.2, 1.3), (5.7, 1.3), (6.3, 1.9), (6.7, 2.5), (5.5, 1.2), (4.9, 1.0), (6.1, 1.4), (6.0, 1.6), (7.2, 2.5), (7.3, 1.8), (6.6, 1.4), (5.6, 2.0), (5.5, 1.0), (6.4, 2.2), (5.6, 1.3), (6.6, 1.3), (6.9, 2.1), (6.8, 2.1), (5.7, 1.3), (7.0, 1.4), (6.1, 1.4), (6.1, 1.8), (6.7, 1.7), (6.0, 1.5), (6.5, 1.8), (6.4, 1.5), (6.9, 1.5), (5.6, 1.3), (6.7, 1.4), (5.8, 1.9), (6.3, 1.3), (6.7, 2.1), (6.2, 2.3), (6.3, 2.4), (6.7, 1.8), (6.4, 2.3), (6.2, 1.5), (6.1, 1.4), (7.1, 2.1), (5.7, 1.0), (6.8, 1.4), (6.8, 2.3), (5.1, 1.1), (4.9, 1.7), (5.9, 1.8), (7.4, 1.9), (6.5, 2.0), (6.7, 1.5), (6.5, 2.0), (5.8, 1.0), (6.4, 2.1), (7.6, 2.1), (5.8, 2.4), (7.7, 2.2), (6.3, 1.5), (5.0, 1.0), (6.3, 1.6), (7.7, 2.3), (6.4, 1.9), (6.5, 2.2), (5.7, 1.2), (6.9, 2.3), (5.7, 1.3), (6.1, 1.2), (5.4, 1.5), (5.2, 1.4), (6.7, 2.3), (7.9, 2.0), (5.6, 1.1), (7.2, 1.8), (5.5, 1.3), (7.2, 1.6), (6.3, 2.5), (6.3, 1.8), (6.7, 2.4), (5.0, 1.0), (6.4, 1.8), (6.9, 2.3), (5.5, 1.3), (5.5, 1.1), (5.9, 1.5), (6.0, 1.5), (5.9, 1.8)])\n",
    "data_y = np.array([-1, -1, -1, -1, -1, 1, 1, -1, -1, 1, 1, -1, 1, 1, -1, 1, -1, -1, -1, 1, 1, -1, -1, -1, -1, 1, 1, -1, 1, -1, 1, -1, -1, 1, 1, -1, -1, 1, 1, -1, 1, 1, -1, -1, -1, -1, 1, -1, 1, 1, 1, 1, 1, -1, -1, 1, -1, -1, 1, -1, 1, -1, 1, 1, -1, 1, -1, 1, 1, 1, 1, 1, -1, -1, 1, 1, 1, -1, 1, -1, -1, -1, -1, 1, 1, -1, 1, -1, 1, 1, 1, 1, -1, 1, 1, -1, -1, -1, -1, 1])\n",
    "\n",
    "x_train = np.array([[1, x[0], x[1]] for x in data_x])\n",
    "y_train = np.array(data_y)\n",
    "\n",
    "n_train = len(x_train)  # размер обучающей выборки\n",
    "w = [0.0, 0.0, 0.0]  # начальные весовые коэффициенты\n",
    "nt = np.array([0.5, 0.01, 0.01])  # шаг обучения для каждого параметра w0, w1, w2\n",
    "lm = 0.01  # значение параметра лямбда для вычисления скользящего экспоненциального среднего\n",
    "N = 500  # число итераций алгоритма SGD\n",
    "batch_size = 10 # размер мини-батча (величина K = 10)\n",
    "\n",
    "np.random.seed(0) # генерация одинаковых последовательностей псевдослучайных чисел\n",
    "\n",
    "# здесь продолжайте программу\n",
    "Qe=sum(loss(w, x_train[i], y_train[i]) for i in range(n_train))/n_train\n",
    "for i in range(N):\n",
    "    k=np.random.randint(0, n_train-batch_size-1)\n",
    "    L=sum(loss(w, x_train[i], y_train[i]) for i in range(k,k+batch_size))/batch_size\n",
    "    Qe=lm*L+(1-lm)*Qe\n",
    "    dL=sum(df(w, x_train[i], y_train[i]) for i in range(k,k+batch_size))/batch_size\n",
    "    w=w-nt*dL\n",
    "Q=(np.dot(w, x_train.T)*y_train<0).mean()\n",
    "\n",
    "\n",
    "\n",
    "data_xc1=np.array(data_x[data_y>0])\n",
    "data_xc2=np.array(data_x[data_y<0])\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(data_xc1[:,0], data_xc1[:,1], c=\"r\")\n",
    "plt.scatter(data_xc2[:,0], data_xc2[:,1], c=\"b\")    \n",
    "plt.axline((5,-5*w[1]/w[2]-w[0]/w[2]),(4,-4*(w[1]/w[2])-w[0]/w[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0672e1b2-ef51-47c0-bf5a-84c8c8bd3cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def func(x):\n",
    "    return 0.4 * x + 0.1 * np.sin(2*x) + 0.2 * np.cos(3*x)\n",
    "\n",
    "def df(x):\n",
    "    return 0.4 + 0.2*np.cos(2*x) - 0.6*np.sin(3*x)\n",
    "\n",
    "# здесь объявляйте функцию df (производную) и продолжайте программу\n",
    "\n",
    "eta=1.0\n",
    "x=4.0\n",
    "N=500\n",
    "lm=0.7\n",
    "v=0\n",
    "\n",
    "for i in range(N):\n",
    "    v=v*lm+(1-lm)*df(x-lm*v)\n",
    "    x-=v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520169f5-6ec9-435b-9e18-ec9ac27f811f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def func(x):\n",
    "    return -0.5 * x + 0.2 * x ** 2 - 0.01 * x ** 3 - 0.3 * np.sin(4*x)\n",
    "\n",
    "\n",
    "# здесь объявляйте функцию df (производную) и продолжайте программу\n",
    "def df(x):\n",
    "    return -0.5 + 0.4*x + 0.03*x**2 - 1.2*np.cos(4*x)\n",
    "\n",
    "eta=0.1\n",
    "x=-3.5\n",
    "N=200\n",
    "lm=0.9\n",
    "v=0\n",
    "\n",
    "for i in range(N):\n",
    "    v=v*lm+(1-lm)*eta*df(x)\n",
    "    x-=v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb330e2-ef4f-4e1e-abed-8fb3219a7cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def func(x):\n",
    "    return 2 * x + 0.1 * x ** 3 + 2 * np.cos(3*x)\n",
    "\n",
    "def df(x):\n",
    "    return 2 + 0.3*x**2 - 6*np.sin(3*x)\n",
    "\n",
    "eta=0.5\n",
    "x=4\n",
    "N=200\n",
    "lm=0.8\n",
    "G=0\n",
    "e=0.01\n",
    "\n",
    "for i in range(N):\n",
    "    G=lm*G+(1-lm)*df(x)**2\n",
    "    x-=eta*(df(x)/(G**0.5+e))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573b1582-3107-40d1-b42d-5f5213eb1256",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# исходная функция, которую нужно аппроксимировать моделью a(x)\n",
    "def func(x):\n",
    "    return -0.7 * x - 0.2 * x ** 2 + 0.05 * x ** 3 - 0.2 * np.cos(3 * x) + 2\n",
    "\n",
    "\n",
    "# здесь объявляйте необходимые функции\n",
    "def x(x):\n",
    "    return np.array([1, x, x**2, x**3])\n",
    "\n",
    "def dQ(w, k):\n",
    "    global gamma, v, coord_x, coord_y, batch_size\n",
    "    c1=w-gamma*v\n",
    "    c2=(2/batch_size)*sum(np.dot(np.dot(c1,x(coord_x[i]).T)-coord_y[i], x(coord_x[i])) for i in range(k, k+batch_size))\n",
    "    return c2\n",
    "\n",
    "def Q(w, k):\n",
    "    global gamma, v, coord_x, coord_y, batch_size\n",
    "    return (1/batch_size) * sum((np.dot(w, x(coord_x[i]))-coord_y[i])**2 for i in range(k, k+batch_size))\n",
    "\n",
    "coord_x = np.arange(-4.0, 6.0, 0.1) # значения по оси абсцисс [-4; 6] с шагом 0.1\n",
    "coord_y = func(coord_x) # значения функции по оси ординат\n",
    "\n",
    "sz = len(coord_x)\t# количество значений функций (точек)\n",
    "eta = np.array([0.1, 0.01, 0.001, 0.0001]) # шаг обучения для каждого параметра w0, w1, w2, w3\n",
    "w = np.array([0., 0., 0., 0.]) # начальные значения параметров модели\n",
    "N = 500 # число итераций алгоритма SGD\n",
    "lm = 0.02 # значение параметра лямбда для вычисления скользящего экспоненциального среднего\n",
    "batch_size = 20 # размер мини-батча (величина K = 20)\n",
    "gamma = 0.8 # коэффициент гамма для вычисления импульсов Нестерова\n",
    "v = np.zeros(len(w))  # начальное значение [0, 0, 0, 0]\n",
    "\n",
    "Qe = (1/sz) * sum((np.dot(w, x(coord_x[i]))-coord_y[i])**2 for i in range(sz))\n",
    "np.random.seed(0) # генерация одинаковых последовательностей псевдослучайных чисел\n",
    "\n",
    "# здесь продолжайте программу\n",
    "\n",
    "for i in range(N):\n",
    "    k=np.random.randint(0,sz-batch_size-1)\n",
    "    v=gamma*v+(1-gamma)*eta*dQ(w-gamma*v, k)\n",
    "    w-=v\n",
    "    Qe=lm*Q(w, k)+(1-lm)*Qe\n",
    "xx=np.array([x(coord_x[i]) for i in range(len(coord_x))])\n",
    "Q=((np.dot(w, xx.T)-coord_y)**2).mean()\n",
    "print(Qe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cd3d3bf-3207-48c6-a7e0-776f982f489a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.lines.AxLine at 0x191d9ba1790>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# логарифмическая функция потерь\n",
    "def loss(w, x, y):\n",
    "    M = np.dot(w, x) * y\n",
    "    return np.log2(1 + np.exp(-M))\n",
    "\n",
    "\n",
    "# производная логарифмической функции потерь по вектору w\n",
    "def df(w, x, y):\n",
    "    M = np.dot(w, x) * y\n",
    "    return -(np.exp(-M) * x.T * y) / ((1 + np.exp(-M)) * np.log(2))\n",
    "\n",
    "\n",
    "data_x = [(5.3, 2.3), (5.7, 2.5), (4.0, 1.0), (5.6, 2.4), (4.5, 1.5), (5.4, 2.3), (4.8, 1.8), (4.5, 1.5), (5.1, 1.5), (6.1, 2.3), (5.1, 1.9), (4.0, 1.2), (5.2, 2.0), (3.9, 1.4), (4.2, 1.2), (4.7, 1.5), (4.8, 1.8), (3.6, 1.3), (4.6, 1.4), (4.5, 1.7), (3.0, 1.1), (4.3, 1.3), (4.5, 1.3), (5.5, 2.1), (3.5, 1.0), (5.6, 2.2), (4.2, 1.5), (5.8, 1.8), (5.5, 1.8), (5.7, 2.3), (6.4, 2.0), (5.0, 1.7), (6.7, 2.0), (4.0, 1.3), (4.4, 1.4), (4.5, 1.5), (5.6, 2.4), (5.8, 1.6), (4.6, 1.3), (4.1, 1.3), (5.1, 2.3), (5.2, 2.3), (5.6, 1.4), (5.1, 1.8), (4.9, 1.5), (6.7, 2.2), (4.4, 1.3), (3.9, 1.1), (6.3, 1.8), (6.0, 1.8), (4.5, 1.6), (6.6, 2.1), (4.1, 1.3), (4.5, 1.5), (6.1, 2.5), (4.1, 1.0), (4.4, 1.2), (5.4, 2.1), (5.0, 1.5), (5.0, 2.0), (4.9, 1.5), (5.9, 2.1), (4.3, 1.3), (4.0, 1.3), (4.9, 2.0), (4.9, 1.8), (4.0, 1.3), (5.5, 1.8), (3.7, 1.0), (6.9, 2.3), (5.7, 2.1), (5.3, 1.9), (4.4, 1.4), (5.6, 1.8), (3.3, 1.0), (4.8, 1.8), (6.0, 2.5), (5.9, 2.3), (4.9, 1.8), (3.3, 1.0), (3.9, 1.2), (5.6, 2.1), (5.8, 2.2), (3.8, 1.1), (3.5, 1.0), (4.5, 1.5), (5.1, 1.9), (4.7, 1.4), (5.1, 1.6), (5.1, 2.0), (4.8, 1.4), (5.0, 1.9), (5.1, 2.4), (4.6, 1.5), (6.1, 1.9), (4.7, 1.6), (4.7, 1.4), (4.7, 1.2), (4.2, 1.3), (4.2, 1.3)]\n",
    "data_y = [1, 1, -1, 1, -1, 1, 1, -1, 1, 1, 1, -1, 1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, 1, -1, 1, -1, 1, 1, 1, 1, -1, 1, -1, -1, -1, 1, 1, -1, -1, 1, 1, 1, 1, -1, 1, -1, -1, 1, 1, -1, 1, -1, -1, 1, -1, -1, 1, 1, 1, -1, 1, -1, -1, 1, 1, -1, 1, -1, 1, 1, 1, -1, 1, -1, 1, 1, 1, 1, -1, -1, 1, 1, -1, -1, -1, 1, -1, -1, 1, -1, 1, 1, -1, 1, -1, -1, -1, -1, -1]\n",
    "\n",
    "x_train = np.array([[1, x[0], x[1]] for x in data_x])\n",
    "y_train = np.array(data_y)\n",
    "\n",
    "n_train = len(x_train)  # размер обучающей выборки\n",
    "w = [0.0, 0.0, 0.0]  # начальные весовые коэффициенты\n",
    "nt = np.array([0.1, 0.05, 0.05])  # шаг обучения для каждого параметра w0, w1, w2\n",
    "lm = 0.01  # значение параметра лямбда для вычисления скользящего экспоненциального среднего\n",
    "N = 200  # число итераций алгоритма SGD\n",
    "batch_size = 10 # размер мини-батча (величина K = 10)\n",
    "\n",
    "alpha = 0.7 # параметр для RMSProp\n",
    "G = np.zeros(len(w))  # параметр для RMSProp\n",
    "eps = 0.01 # параметр для RMSProp\n",
    "\n",
    "Qe = (1/n_train)*np.sum(loss(w, x_train.T, y_train))\n",
    "np.random.seed(0) # генерация одинаковых последовательностей псевдослучайных чисел\n",
    "\n",
    "for i in range(N):\n",
    "    k=np.random.randint(0, n_train-batch_size-1)\n",
    "    Qk=(loss(w, x_train.T, y_train)).mean()\n",
    "    dQ=(1/batch_size)*sum(df(w, x_train[i], y_train[i]) for i in range(k,k+batch_size))\n",
    "    G=alpha*G+(1-alpha)*dQ*dQ\n",
    "    w-=nt*dQ/(np.sqrt(G)+eps)\n",
    "    Qe=lm*Qk+(1-lm)*Qe\n",
    "Q=(w @ x_train.T * y_train < 0).mean()\n",
    "data_xc1=np.array(x_train[y_train>0])\n",
    "data_xc2=np.array(x_train[y_train<0])\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(data_xc1[:,1], data_xc1[:,2], c=\"r\")\n",
    "plt.scatter(data_xc2[:,1], data_xc2[:,2], c=\"b\")    \n",
    "plt.axline((5,-5*w[1]/w[2]-w[0]/w[2]),(4,-4*(w[1]/w[2])-w[0]/w[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe78481-a426-4176-bc99-beeab858bb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def func(x):\n",
    "    return 0.1 * x + 0.1 * x ** 2 - 0.5 * np.sin(2*x) + 1 * np.cos(4*x) + 10\n",
    "\n",
    "def L(w, x, y):\n",
    "    global lm\n",
    "    w1=np.array([0]+[w[i] for i in range(1,len(w))])\n",
    "    return (w @ x.T - y)**2 + lm/2 * (w1 @ w1.T)\n",
    "\n",
    "\n",
    "x = np.arange(-3.0, 4.1, 0.1) # значения по оси абсцисс (Ox) с шагом 0,1\n",
    "y = np.array(func(x)) # значения функции по оси ординат\n",
    "\n",
    "N = 22  # размер признакового пространства (степень полинома N-1)\n",
    "lm = 20  # параметр лямбда для L2-регуляризатора\n",
    "\n",
    "X = np.array([[a ** n for n in range(N)] for a in x])  # матрица входных векторов\n",
    "IL = lm * np.eye(N)  # матрица lambda*I\n",
    "IL[0][0] = 0  # первый коэффициент не регуляризуем\n",
    "\n",
    "X_train = X[::2]  # обучающая выборка (входы)\n",
    "Y_train = y[::2]  # обучающая выборка (целевые значения)\n",
    "\n",
    "w=(np.linalg.inv(X_train.T @ X_train + IL) @ X_train.T) @ Y_train\n",
    "Q=((w @ X.T - y)**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8a6d1f-619b-43e4-8151-f5f6289d7094",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# исходная функция, которую нужно аппроксимировать моделью a(x)\n",
    "def func(x):\n",
    "    return -0.7 * x - 0.2 * x ** 2 + 0.05 * x ** 3 - 0.2 * np.cos(3 * x) + 2\n",
    "\n",
    "\n",
    "# здесь объявляйте необходимые функции\n",
    "def x(x):\n",
    "    return np.array([1, x, x**2, x**3])\n",
    "\n",
    "def dQ(w, k):\n",
    "    global gamma, v, coord_x, coord_y, batch_size\n",
    "    c1=w-gamma*v\n",
    "    c2=(2/batch_size)*sum(np.dot(np.dot(c1,x(coord_x[i]).T)-coord_y[i], x(coord_x[i])) for i in range(k, k+batch_size))\n",
    "    return c2\n",
    "\n",
    "def Q(w, k):\n",
    "    global gamma, v, coord_x, coord_y, batch_size\n",
    "    return (1/batch_size) * sum((np.dot(w, x(coord_x[i]))-coord_y[i])**2 for i in range(k, k+batch_size))\n",
    "\n",
    "coord_x = np.arange(-4.0, 6.0, 0.1) # значения по оси абсцисс [-4; 6] с шагом 0.1\n",
    "coord_y = func(coord_x) # значения функции по оси ординат\n",
    "\n",
    "sz = len(coord_x)\t# количество значений функций (точек)\n",
    "eta = np.array([0.1, 0.01, 0.001, 0.0001]) # шаг обучения для каждого параметра w0, w1, w2, w3\n",
    "w = np.array([0., 0., 0., 0.]) # начальные значения параметров модели\n",
    "N = 500 # число итераций алгоритма SGD\n",
    "lm = 0.02 # значение параметра лямбда для вычисления скользящего экспоненциального среднего\n",
    "batch_size = 20 # размер мини-батча (величина K = 20)\n",
    "gamma = 0.8 # коэффициент гамма для вычисления импульсов Нестерова\n",
    "v = np.zeros(len(w))  # начальное значение [0, 0, 0, 0]\n",
    "\n",
    "Qe = (1/sz) * sum((np.dot(w, x(coord_x[i]))-coord_y[i])**2 for i in range(sz))\n",
    "np.random.seed(0) # генерация одинаковых последовательностей псевдослучайных чисел\n",
    "\n",
    "# здесь продолжайте программу\n",
    "\n",
    "for i in range(N):\n",
    "    k=np.random.randint(0,sz-batch_size-1)\n",
    "    v=gamma*v+(1-gamma)*eta*dQ(w-gamma*v, k)\n",
    "    w-=v\n",
    "    Qe=lm*Q(w, k)+(1-lm)*Qe\n",
    "xx=np.array([x(coord_x[i]) for i in range(len(coord_x))])\n",
    "Q=((np.dot(w, xx.T)-coord_y)**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7f47fd-f08e-4a14-a1d8-b45217706ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def func(x):\n",
    "    return -0.7 * x - 0.2 * x ** 2 + 0.05 * x ** 3 - 0.2 * np.cos(3 * x) + 2\n",
    "\n",
    "def model_a(X, w):\n",
    "    return X @ w\n",
    "\n",
    "def loss(y_pred, y_true):\n",
    "    return np.mean(np.square(y_pred - y_true))\n",
    "\n",
    "def gradient(X, y, w):\n",
    "    return  (2 / X.shape[0]) * X.T @ (model_a(X, w) - y)\n",
    "\n",
    "# Заданные значения по оси абсцисс [-4; 6] с шагом 0.1\n",
    "coord_x = np.arange(-4.0, 6.0, 0.1)\n",
    "coord_y = func(coord_x)  # значения функции по оси ординат\n",
    "sz = len(coord_x)  # количество значений функций (точек)\n",
    "\n",
    "# Формирование полной выборки\n",
    "X_train = np.array([[1, x, x**2, x**3] for x in coord_x])\n",
    "y_train = np.array(coord_y)\n",
    "\n",
    "# Начальные параметры\n",
    "eta = np.array([0.1, 0.01, 0.001, 0.0001])  # шаг обучения для каждого параметра w0, w1, w2, w3\n",
    "w = np.array([0., 0., 0., 0.])              # начальные значения параметров модели\n",
    "N = 500                                     # число итераций алгоритма SGD\n",
    "lm = 0.02                                   # значение параметра лямбда для вычисления скользящего экспоненциального среднего\n",
    "batch_size = 20                             # размер мини-батча\n",
    "gamma = 0.8                                 # коэффициент гамма для вычисления импульсов Нестерова\n",
    "v = np.zeros(len(w))                        # начальное значение для импульсов Нестерова\n",
    "\n",
    "np.random.seed(0)  # генерация одинаковых последовательностей псевдослучайных чисел\n",
    "\n",
    "Qe = loss(model_a(X_train, w), y_train)  # начальное значение среднего эмпирического риска\n",
    "\n",
    "# Градиентный спуск с импульсами Нестерова\n",
    "for epoch in range(N):\n",
    "    # Формирование батча\n",
    "    k = np.random.randint(0, sz - batch_size - 1)  # случайный выбор начального индекса для батча\n",
    "    X_batch = X_train[k:k+batch_size]\n",
    "    y_batch = y_train[k:k+batch_size]\n",
    "\n",
    "    # Вычисление показателя качества на батче\n",
    "    Qk = loss(model_a(X_batch, w), y_batch)\n",
    "    Qe = lm * Qk + (1 - lm) * Qe  # обновление скользящего среднего\n",
    "\n",
    "    # Коррекция весов с учетом импульса Нестерова\n",
    "    v = gamma * v + (1 - gamma) * eta * gradient(X_batch, y_batch, w - gamma * v)\n",
    "    w -= v\n",
    "\n",
    "Q = loss(model_a(X_train, w), y_train)  # итоговое значение среднего эмпирического риска\n",
    "# print(f'w = {list(w)}\\nQe = {Qe}\\nQ = {Q}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5efc79a-5ee0-446d-8e86-1a7a5b60ba1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# исходная функция, которую нужно аппроксимировать моделью a(x)\n",
    "def func(x):\n",
    "    return 0.5 * x + 0.2 * x ** 2 - 0.05 * x ** 3 + 0.2 * np.sin(4 * x) - 2.5\n",
    "\n",
    "\n",
    "# модель\n",
    "def model(w, x):\n",
    "    xv = np.array([x ** n for n in range(len(w))])\n",
    "    return w @ xv.T\n",
    "\n",
    "\n",
    "# функция потерь\n",
    "def loss(w, x, y):\n",
    "    return (model(w, x) - y) ** 2\n",
    "\n",
    "\n",
    "# производная функции потерь\n",
    "def dL(w, x, y):\n",
    "    xv = np.array([x ** n for n in range(len(w))])\n",
    "    return 2 * (model(w, x) - y) * xv\n",
    "\n",
    "def x(x):\n",
    "    return np.array([1, x, x**2, x**3, x**4])\n",
    "\n",
    "coord_x = np.arange(-4.0, 6.0, 0.1) # значения по оси абсцисс [-4; 6] с шагом 0.1\n",
    "coord_y = func(coord_x) # значения функции по оси ординат\n",
    "\n",
    "N = 5 # сложность модели (полином степени N-1)\n",
    "lm_l2 = 2 # коэффициент лямбда для L2-регуляризатора\n",
    "sz = len(coord_x)\t# количество значений функций (точек)\n",
    "eta = np.array([0.1, 0.01, 0.001, 0.0001, 0.000002]) # шаг обучения для каждого параметра w0, w1, w2, w3, w4\n",
    "w = np.zeros(N) # начальные нулевые значения параметров модели\n",
    "n_iter = 500 # число итераций алгоритма SGD\n",
    "lm = 0.02 # значение параметра лямбда для вычисления скользящего экспоненциального среднего\n",
    "batch_size = 20 # размер мини-батча (величина K = 20)\n",
    "\n",
    "# здесь продолжайте программу\n",
    "Qe = (loss(w, coord_x[1], coord_y[1])).mean()\n",
    "np.random.seed(0) # генерация одинаковых последовательностей псевдослучайных чисел\n",
    "\n",
    "# здесь продолжайте программу\n",
    "I=np.ones(N)\n",
    "I[0]=0\n",
    "for i in range(n_iter):\n",
    "    k = np.random.randint(0, sz-batch_size-1)\n",
    "    Qk = sum(loss(w, coord_x[i], coord_y[i]) for i in range(k,k+batch_size))/batch_size\n",
    "    Qe = lm * Qk + (1-lm)*Qe\n",
    "    kdl=sum(dL(w, coord_x[i], coord_y[i]) for i in range(k,k+batch_size))/batch_size\n",
    "    w -= eta * (kdl + lm_l2 * I * w)\n",
    "Q = sum((model(w, coord_x[i]) - coord_y[i])**2 for i in range(sz))/sz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8aa210-1a10-4b2e-917e-271cf46d7bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# логарифмическая функция потерь\n",
    "def loss(w, x, y):\n",
    "    M = np.dot(w, x) * y\n",
    "    return np.log2(1 + np.exp(-M))\n",
    "\n",
    "\n",
    "# производная логарифмической функции потерь по вектору w\n",
    "def df(w, x, y):\n",
    "    M = np.dot(w, x) * y\n",
    "    return -(np.exp(-M) * x.T * y) / ((1 + np.exp(-M)) * np.log(2))\n",
    "\n",
    "\n",
    "data_x = [(5.8, 1.2), (5.6, 1.5), (6.5, 1.5), (6.1, 1.3), (6.4, 1.3), (7.7, 2.0), (6.0, 1.8), (5.6, 1.3), (6.0, 1.6), (5.8, 1.9), (5.7, 2.0), (6.3, 1.5), (6.2, 1.8), (7.7, 2.3), (5.8, 1.2), (6.3, 1.8), (6.0, 1.0), (6.2, 1.3), (5.7, 1.3), (6.3, 1.9), (6.7, 2.5), (5.5, 1.2), (4.9, 1.0), (6.1, 1.4), (6.0, 1.6), (7.2, 2.5), (7.3, 1.8), (6.6, 1.4), (5.6, 2.0), (5.5, 1.0), (6.4, 2.2), (5.6, 1.3), (6.6, 1.3), (6.9, 2.1), (6.8, 2.1), (5.7, 1.3), (7.0, 1.4), (6.1, 1.4), (6.1, 1.8), (6.7, 1.7), (6.0, 1.5), (6.5, 1.8), (6.4, 1.5), (6.9, 1.5), (5.6, 1.3), (6.7, 1.4), (5.8, 1.9), (6.3, 1.3), (6.7, 2.1), (6.2, 2.3), (6.3, 2.4), (6.7, 1.8), (6.4, 2.3), (6.2, 1.5), (6.1, 1.4), (7.1, 2.1), (5.7, 1.0), (6.8, 1.4), (6.8, 2.3), (5.1, 1.1), (4.9, 1.7), (5.9, 1.8), (7.4, 1.9), (6.5, 2.0), (6.7, 1.5), (6.5, 2.0), (5.8, 1.0), (6.4, 2.1), (7.6, 2.1), (5.8, 2.4), (7.7, 2.2), (6.3, 1.5), (5.0, 1.0), (6.3, 1.6), (7.7, 2.3), (6.4, 1.9), (6.5, 2.2), (5.7, 1.2), (6.9, 2.3), (5.7, 1.3), (6.1, 1.2), (5.4, 1.5), (5.2, 1.4), (6.7, 2.3), (7.9, 2.0), (5.6, 1.1), (7.2, 1.8), (5.5, 1.3), (7.2, 1.6), (6.3, 2.5), (6.3, 1.8), (6.7, 2.4), (5.0, 1.0), (6.4, 1.8), (6.9, 2.3), (5.5, 1.3), (5.5, 1.1), (5.9, 1.5), (6.0, 1.5), (5.9, 1.8)]\n",
    "data_y = [-1, -1, -1, -1, -1, 1, 1, -1, -1, 1, 1, -1, 1, 1, -1, 1, -1, -1, -1, 1, 1, -1, -1, -1, -1, 1, 1, -1, 1, -1, 1, -1, -1, 1, 1, -1, -1, 1, 1, -1, 1, 1, -1, -1, -1, -1, 1, -1, 1, 1, 1, 1, 1, -1, -1, 1, -1, -1, 1, -1, 1, -1, 1, 1, -1, 1, -1, 1, 1, 1, 1, 1, -1, -1, 1, 1, 1, -1, 1, -1, -1, -1, -1, 1, 1, -1, 1, -1, 1, 1, 1, 1, -1, 1, 1, -1, -1, -1, -1, 1]\n",
    "\n",
    "x_train = np.array([[1, x[0], x[1], 0.8*x[0], (x[0]+x[1])/2] for x in data_x])\n",
    "y_train = np.array(data_y)\n",
    "\n",
    "n_train = len(x_train)  # размер обучающей выборки\n",
    "w = np.zeros(len(x_train[0]))  # начальные нулевые весовые коэффициенты\n",
    "nt = np.array([0.5] + [0.01] * (len(w) - 1))  # шаг обучения для каждого параметра w0, w1, w2, ...\n",
    "lm = 0.01  # значение параметра лямбда для вычисления скользящего экспоненциального среднего\n",
    "N = 500  # число итераций алгоритма SGD\n",
    "batch_size = 10 # размер мини-батча (величина K = 10)\n",
    "lm_l1 = 0.05 # параметр лямбда для L1-регуляризатора\n",
    "\n",
    "I=np.ones(len(x_train[0]))\n",
    "I[0]=0\n",
    "Qe = sum(loss(w, x.T, y) for x, y in zip(x_train, y_train))/n_train\n",
    "np.random.seed(0) # генерация одинаковых последовательностей псевдослучайных чисел\n",
    "\n",
    "# здесь продолжайте программу\n",
    "for i in range(N):\n",
    "    k=np.random.randint(0, n_train-batch_size-1)\n",
    "    Qk=sum(loss(w, x.T, y) for x, y in zip(x_train[k:k+batch_size:], y_train[k:k+batch_size:]))/batch_size\n",
    "    Qe=lm*Qk+(1-lm)*Qe\n",
    "    dQk=sum(df(w, x.T, y) for x, y in zip(x_train[k:k+batch_size:], y_train[k:k+batch_size:]))/batch_size\n",
    "    w -= nt*(dQk+lm_l1*np.sign(w*I))\n",
    "Q=(w @ x_train.T * y_train < 0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ad613ccd-8cf2-434f-9af6-e63b5263c194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5230972393059328\n",
      "[ 6.79170892e+00  1.40476478e-01 -3.95434175e-01  7.61240428e-02\n",
      " -6.75229103e-03  1.17597278e-03]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# исходная функция, которую нужно аппроксимировать моделью a(x)\n",
    "def func(x):\n",
    "    return -0.5 * x ** 2 + 0.1 * x ** 3 + np.cos(3 * x) + 7\n",
    "\n",
    "# модель\n",
    "def model(w, x):\n",
    "    return w @ np.array([x ** n for n in range(len(w))])\n",
    "\n",
    "coord_x = np.arange(-4.0, 6.0, 0.1)\n",
    "\n",
    "N = 6 # сложность модели (полином степени N-1)\n",
    "sz = len(coord_x)\t# количество значений функций (точек)\n",
    "eta = np.array([0.001, 0.0001, 0.00001, 0.000001, 0.000001, 0.000000001]) # шаг обучения для каждого параметра w0, w1, w2, w3, w4\n",
    "w = np.zeros(N) # начальные нулевые значения параметров модели\n",
    "\n",
    "np.random.seed(0) # генерация одинаковых последовательностей псевдослучайных чисел\n",
    "\n",
    "for i in range(100000):\n",
    "    x = coord_x[np.random.randint(0, sz - 1)]\n",
    "    dp = func(x) - model(w, x)\n",
    "    w += eta * np.array([x ** n for n in range(len(w))]) * dp\n",
    "print(np.mean((coord_y - model(w, coord_x)) ** 2))\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb9a014-2f9d-4be9-b7c5-5c0c185fe6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "data_x = [(7.2, 2.5), (6.4, 2.2), (6.3, 1.5), (7.7, 2.2), (6.2, 1.8), (5.7, 1.3), (7.1, 2.1), (5.8, 2.4), (5.2, 1.4), (5.9, 1.5), (7.0, 1.4), (6.8, 2.1), (7.2, 1.6), (6.7, 2.4), (6.0, 1.5), (5.1, 1.1), (6.6, 1.3), (6.1, 1.4), (6.7, 2.1), (6.4, 1.8), (5.6, 1.3), (6.9, 2.3), (6.4, 1.9), (6.9, 2.3), (6.5, 2.2), (6.0, 1.5), (5.6, 1.1), (5.6, 1.5), (6.0, 1.0), (6.0, 1.8), (6.7, 2.5), (7.7, 2.3), (5.5, 1.1), (5.8, 1.0), (6.9, 2.1), (6.6, 1.4), (6.3, 1.6), (6.1, 1.4), (5.0, 1.0), (7.7, 2.0), (4.9, 1.7), (7.2, 1.8), (6.8, 1.4), (6.1, 1.2), (5.8, 1.9), (6.3, 2.5), (5.7, 2.0), (6.5, 1.8), (7.6, 2.1), (6.3, 1.5), (6.7, 1.4), (6.4, 2.3), (6.2, 2.3), (6.3, 1.9), (5.5, 1.3), (7.9, 2.0), (6.7, 1.8), (6.4, 1.3), (6.5, 2.0), (6.5, 1.5), (6.9, 1.5), (5.6, 1.3), (5.8, 1.2), (6.7, 2.3), (6.0, 1.6), (5.7, 1.2), (5.7, 1.0), (5.5, 1.0), (6.1, 1.4), (6.3, 1.8), (5.7, 1.3), (6.1, 1.3), (5.5, 1.3), (6.3, 1.3), (5.9, 1.8), (7.7, 2.3), (6.5, 2.0), (5.6, 2.0), (6.7, 1.7), (5.7, 1.3), (5.5, 1.2), (5.0, 1.0), (5.8, 1.9), (6.2, 1.3), (6.2, 1.5), (6.3, 2.4), (6.4, 1.5), (7.4, 1.9), (6.8, 2.3), (5.6, 1.3), (5.8, 1.2), (7.3, 1.8), (6.7, 1.5), (6.3, 1.8), (6.0, 1.6), (6.4, 2.1), (6.1, 1.8), (5.9, 1.8), (5.4, 1.5), (4.9, 1.0)]\n",
    "data_y = [1, 1, 1, 1, 1, -1, 1, 1, -1, -1, -1, 1, 1, 1, -1, -1, -1, 1, 1, 1, -1, 1, 1, 1, 1, 1, -1, -1, -1, 1, 1, 1, -1, -1, 1, -1, -1, -1, -1, 1, 1, 1, -1, -1, 1, 1, 1, 1, 1, -1, -1, 1, 1, 1, -1, 1, 1, -1, 1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, 1, 1, 1, 1, -1, -1, -1, -1, 1, -1, -1, 1, -1, 1, 1, -1, -1, 1, -1, 1, -1, 1, 1, -1, -1, -1]\n",
    "\n",
    "x_train = np.array(data_x)\n",
    "y_train = np.array(data_y)\n",
    "\n",
    "# математические ожидания\n",
    "mx11, mx12 = np.mean(x_train[y_train == -1], axis=0)\n",
    "mx21, mx22 = np.mean(x_train[y_train == 1], axis=0)\n",
    "\n",
    "# дисперсии\n",
    "Dx11, Dx12 = np.var(x_train[y_train == -1], axis=0)\n",
    "Dx21, Dx22 = np.var(x_train[y_train == 1], axis=0)\n",
    "\n",
    "lm1 = 1     # штраф неверной классификации 1-го класса (-1)\n",
    "lm2 = 1     # штраф неверной классификации 2-го класса (+1)\n",
    "P1 = 0.5    # априорная вероятность появления образов 1-го класса\n",
    "P2 = 1 - P1 # априорная вероятность появления образов 2-го класса\n",
    "\n",
    "# здесь продолжайте программу\n",
    "\n",
    "def p__(x):\n",
    "    global mx11, mx12, mx21, mx22, Dx11, Dx12, Dx21, Dx22\n",
    "    s1=(1/(2*np.pi*np.sqrt(Dx11+Dx12)))\n",
    "    s2=(x[0]-mx11)**2/2/Dx11\n",
    "    s3=(x[1]-mx12)**2/2/Dx12\n",
    "    return s1+np.exp(-s2-s3)\n",
    "\n",
    "def p_(x):\n",
    "    global mx11, mx12, mx21, mx22, Dx11, Dx12, Dx21, Dx22\n",
    "    s1=(1/(2*np.pi*np.sqrt(Dx21+Dx22)))\n",
    "    s2=(x[0]-mx21)**2/2/Dx21\n",
    "    s3=(x[1]-mx22)**2/2/Dx22\n",
    "    return s1+np.exp(-s2-s3)\n",
    "\n",
    "a1=np.argmax(np.log(lm1*P1) + np.sum(np.log(p__(x_train[y_train==-1]))))\n",
    "a2=np.argmax(np.log(lm2*P2) + np.sum(np.log(p_(x_train[y_train==1]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee72d2e-465f-42ca-8915-be45130c6054",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "w=np.array([-330, 1, 3, 2, -0.15])\n",
    "x=np.array([1, 240, 80, 1, 1000])\n",
    "def f(w, x):\n",
    "    m = w @ x.T\n",
    "    p = 1/(1+np.exp(-m))\n",
    "    return p\n",
    "print(f(w,x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f6fd57-df4d-4df2-b0c1-88d57107d9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "data_x = [(7.2, 2.5), (6.4, 2.2), (6.3, 1.5), (7.7, 2.2), (6.2, 1.8), (5.7, 1.3), (7.1, 2.1), (5.8, 2.4), (5.2, 1.4), (5.9, 1.5), (7.0, 1.4), (6.8, 2.1), (7.2, 1.6), (6.7, 2.4), (6.0, 1.5), (5.1, 1.1), (6.6, 1.3), (6.1, 1.4), (6.7, 2.1), (6.4, 1.8), (5.6, 1.3), (6.9, 2.3), (6.4, 1.9), (6.9, 2.3), (6.5, 2.2), (6.0, 1.5), (5.6, 1.1), (5.6, 1.5), (6.0, 1.0), (6.0, 1.8), (6.7, 2.5), (7.7, 2.3), (5.5, 1.1), (5.8, 1.0), (6.9, 2.1), (6.6, 1.4), (6.3, 1.6), (6.1, 1.4), (5.0, 1.0), (7.7, 2.0), (4.9, 1.7), (7.2, 1.8), (6.8, 1.4), (6.1, 1.2), (5.8, 1.9), (6.3, 2.5), (5.7, 2.0), (6.5, 1.8), (7.6, 2.1), (6.3, 1.5), (6.7, 1.4), (6.4, 2.3), (6.2, 2.3), (6.3, 1.9), (5.5, 1.3), (7.9, 2.0), (6.7, 1.8), (6.4, 1.3), (6.5, 2.0), (6.5, 1.5), (6.9, 1.5), (5.6, 1.3), (5.8, 1.2), (6.7, 2.3), (6.0, 1.6), (5.7, 1.2), (5.7, 1.0), (5.5, 1.0), (6.1, 1.4), (6.3, 1.8), (5.7, 1.3), (6.1, 1.3), (5.5, 1.3), (6.3, 1.3), (5.9, 1.8), (7.7, 2.3), (6.5, 2.0), (5.6, 2.0), (6.7, 1.7), (5.7, 1.3), (5.5, 1.2), (5.0, 1.0), (5.8, 1.9), (6.2, 1.3), (6.2, 1.5), (6.3, 2.4), (6.4, 1.5), (7.4, 1.9), (6.8, 2.3), (5.6, 1.3), (5.8, 1.2), (7.3, 1.8), (6.7, 1.5), (6.3, 1.8), (6.0, 1.6), (6.4, 2.1), (6.1, 1.8), (5.9, 1.8), (5.4, 1.5), (4.9, 1.0)]\n",
    "data_y = [1, 1, 1, 1, 1, -1, 1, 1, -1, -1, -1, 1, 1, 1, -1, -1, -1, 1, 1, 1, -1, 1, 1, 1, 1, 1, -1, -1, -1, 1, 1, 1, -1, -1, 1, -1, -1, -1, -1, 1, 1, 1, -1, -1, 1, 1, 1, 1, 1, -1, -1, 1, 1, 1, -1, 1, 1, -1, 1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, 1, 1, 1, 1, -1, -1, -1, -1, 1, -1, -1, 1, -1, 1, 1, -1, -1, 1, -1, 1, -1, 1, 1, -1, -1, -1]\n",
    "\n",
    "x_train = np.array(data_x)\n",
    "y_train = np.array(data_y)\n",
    "\n",
    "# математические ожидания\n",
    "mx11, mx12 = np.mean(x_train[y_train == -1], axis=0)\n",
    "mx21, mx22 = np.mean(x_train[y_train == 1], axis=0)\n",
    "\n",
    "# дисперсии\n",
    "Dx11, Dx12 = np.var(x_train[y_train == -1], axis=0)\n",
    "Dx21, Dx22 = np.var(x_train[y_train == 1], axis=0)\n",
    "\n",
    "lm1 = 1     # штраф неверной классификации 1-го класса (-1)\n",
    "lm2 = 1     # штраф неверной классификации 2-го класса (+1)\n",
    "P1 = 0.5    # априорная вероятность появления образов 1-го класса\n",
    "P2 = 1 - P1 # априорная вероятность появления образов 2-го класса\n",
    "\n",
    "# здесь продолжайте программу\n",
    "\n",
    "def f_y(x):\n",
    "    s1=1/(2*np.pi*np.sqrt(Dx11 * Dx12))\n",
    "    s2=(x[0]-mx11)**2/2/Dx11\n",
    "    s3=(x[1]-mx12)**2/2/Dx12\n",
    "    return s1*np.exp(-s2-s3)\n",
    "    \n",
    "def fy(x):\n",
    "    s1=1/(2*np.pi*np.sqrt(Dx21 * Dx22))\n",
    "    s2=(x[0]-mx21)**2/2/Dx21\n",
    "    s3=(x[1]-mx22)**2/2/Dx22\n",
    "    return s1*np.exp(-s2-s3)\n",
    "\n",
    "predict=np.array([])\n",
    "for i in range(len(x_train)):\n",
    "    pred = [np.log(lm2 * P2) + np.log(f_y(x_train[i])), np.log(lm1 * P1) + np.log(fy(x_train[i]))]\n",
    "    predict = np.append(predict, np.argmax(pred)*2-1)\n",
    "Q = (predict != y_train).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757d1cea-e729-4b71-9abe-b4672957e2a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def func(x):\n",
    "    return 0.5 * x + 0.2 * x ** 2 - 0.05 * x ** 3 + 0.2 * np.sin(4 * x) - 2.5\n",
    "\n",
    "def model(w, x):\n",
    "    return w[0] + w[1] * x + w[2] * x ** 2 + w[3] * x ** 3\n",
    "\n",
    "def loss(w, x, y):\n",
    "    return (x @ w - y) ** 2\n",
    "\n",
    "coord_x = np.arange(-4.0, 6.0, 0.1)\n",
    "\n",
    "x_train = np.array([[_x**i for i in range(4)] for _x in coord_x]) # обучающая выборка\n",
    "y_train = func(coord_x) # целевые выходные значения\n",
    "\n",
    "# здесь продолжайте программу\n",
    "w=np.linalg.inv(x_train.T @ x_train) @ (x_train.T @ y_train)\n",
    "Q = loss(w, x_train, y_train).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af019274-c0e2-45e4-9b44-710eee158121",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.inv(x_train.T @ x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e154613-4d00-4fe6-bd82-5b622b20a807",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "w = np.array([-100, -11120, -100, -1, 87])\n",
    "x = np.array([1, 190, 70, 1, 300])\n",
    "M = -(w @ x.T)\n",
    "print(1 / (1 + np.exp(-M)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b5198d-3eb2-4950-a020-e278d6748f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def p(x, D, x0):\n",
    "    m1 = 1 / (np.sqrt(2 * np.pi * D))\n",
    "    m2 = np.exp(-(x - x0)**2 / 2 / D)\n",
    "    return m1 * m2\n",
    "\n",
    "x = [p(x, 0.5, 7) * p(x, 0.2, 6.5) for x in np.arange(5, 8, 0.01)] \n",
    "print(x.index(max(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5c5c11-ebcb-4ad1-8d79-82b1e9dbf24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "data_x = [(7.2, 2.5), (6.4, 2.2), (6.3, 1.5), (7.7, 2.2), (6.2, 1.8), (5.7, 1.3), (7.1, 2.1), (5.8, 2.4), (5.2, 1.4), (5.9, 1.5), (7.0, 1.4), (6.8, 2.1), (7.2, 1.6), (6.7, 2.4), (6.0, 1.5), (5.1, 1.1), (6.6, 1.3), (6.1, 1.4), (6.7, 2.1), (6.4, 1.8), (5.6, 1.3), (6.9, 2.3), (6.4, 1.9), (6.9, 2.3), (6.5, 2.2), (6.0, 1.5), (5.6, 1.1), (5.6, 1.5), (6.0, 1.0), (6.0, 1.8), (6.7, 2.5), (7.7, 2.3), (5.5, 1.1), (5.8, 1.0), (6.9, 2.1), (6.6, 1.4), (6.3, 1.6), (6.1, 1.4), (5.0, 1.0), (7.7, 2.0), (4.9, 1.7), (7.2, 1.8), (6.8, 1.4), (6.1, 1.2), (5.8, 1.9), (6.3, 2.5), (5.7, 2.0), (6.5, 1.8), (7.6, 2.1), (6.3, 1.5), (6.7, 1.4), (6.4, 2.3), (6.2, 2.3), (6.3, 1.9), (5.5, 1.3), (7.9, 2.0), (6.7, 1.8), (6.4, 1.3), (6.5, 2.0), (6.5, 1.5), (6.9, 1.5), (5.6, 1.3), (5.8, 1.2), (6.7, 2.3), (6.0, 1.6), (5.7, 1.2), (5.7, 1.0), (5.5, 1.0), (6.1, 1.4), (6.3, 1.8), (5.7, 1.3), (6.1, 1.3), (5.5, 1.3), (6.3, 1.3), (5.9, 1.8), (7.7, 2.3), (6.5, 2.0), (5.6, 2.0), (6.7, 1.7), (5.7, 1.3), (5.5, 1.2), (5.0, 1.0), (5.8, 1.9), (6.2, 1.3), (6.2, 1.5), (6.3, 2.4), (6.4, 1.5), (7.4, 1.9), (6.8, 2.3), (5.6, 1.3), (5.8, 1.2), (7.3, 1.8), (6.7, 1.5), (6.3, 1.8), (6.0, 1.6), (6.4, 2.1), (6.1, 1.8), (5.9, 1.8), (5.4, 1.5), (4.9, 1.0)]\n",
    "data_y = [1, 1, 1, 1, 1, -1, 1, 1, -1, -1, -1, 1, 1, 1, -1, -1, -1, 1, 1, 1, -1, 1, 1, 1, 1, 1, -1, -1, -1, 1, 1, 1, -1, -1, 1, -1, -1, -1, -1, 1, 1, 1, -1, -1, 1, 1, 1, 1, 1, -1, -1, 1, 1, 1, -1, 1, 1, -1, 1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, 1, 1, 1, 1, -1, -1, -1, -1, 1, -1, -1, 1, -1, 1, 1, -1, -1, 1, -1, 1, -1, 1, 1, -1, -1, -1]\n",
    "\n",
    "x_train = np.array(data_x)\n",
    "y_train = np.array(data_y)\n",
    "n_train = 100\n",
    "\n",
    "# математические ожидания\n",
    "mx11, mx12 = np.mean(x_train[y_train == -1], axis=0)\n",
    "mx21, mx22 = np.mean(x_train[y_train == 1], axis=0)\n",
    "\n",
    "# дисперсии\n",
    "Dx11, Dx12 = np.var(x_train[y_train == -1], axis=0)\n",
    "Dx21, Dx22 = np.var(x_train[y_train == 1], axis=0)\n",
    "\n",
    "lm1 = 1     # штраф неверной классификации 1-го класса (-1)\n",
    "lm2 = 1     # штраф неверной классификации 2-го класса (+1)\n",
    "P1 = 0.5    # априорная вероятность появления образов 1-го класса\n",
    "P2 = 1 - P1 # априорная вероятность появления образов 2-го класса\n",
    "\n",
    "# здесь продолжайте программу\n",
    "\n",
    "def p(x, cs):\n",
    "    if cs == 1:\n",
    "        D1 = Dx21; D2 = Dx22\n",
    "        m1 = mx21; m2 = mx22\n",
    "    else:\n",
    "        D1 = Dx11; D2 = Dx12\n",
    "        m1 = mx11; m2 = mx12\n",
    "    s1 = 1 / (2 * np.pi * np.sqrt(D1 * D2))\n",
    "    s2 = -(x[0] - m1) ** 2 / 2 / D1\n",
    "    s3 = -(x[1] - m2) ** 2 / 2 / D2\n",
    "    return s1 * np.exp(s2 + s3)\n",
    "\n",
    "def a(x):\n",
    "    return np.argmax(np.array([np.log(lm2 * 0.5) + np.log(p(x, 1)), np.log(lm1 * 0.5) + np.log(p(x, -1))])) \n",
    "\n",
    "predict = np.array([a(x_train[i])*2-1 for i in range(len(x_train))])\n",
    "Q = (predict == y_train).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27172bd-dbd5-4904-b2b5-33ec128c2e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def func(x):\n",
    "    return 0.5 * x + 0.2 * x ** 2 - 0.05 * x ** 3 + 0.2 * np.sin(4 * x) - 2.5\n",
    "\n",
    "\n",
    "def model(w, x):\n",
    "    return w[0] + w[1] * x + w[2] * x ** 2 + w[3] * x ** 3\n",
    "\n",
    "\n",
    "coord_x = np.arange(-4.0, 6.0, 0.1)\n",
    "\n",
    "x_train = np.array([[_x**i for i in range(4)] for _x in coord_x]) # обучающая выборка\n",
    "y_train = func(coord_x) # целевые выходные значения\n",
    "\n",
    "w = np.linalg.inv(x_train @ x_train.T) @ (x_train @ y_train.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6670d8d8-d04f-4ae1-aeed-453c4fb62282",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.array([[1, 2, 3],\n",
    "             [4, 9, 6],\n",
    "             [9, 8, 1]])\n",
    "b1 = np.linalg.inv(b)\n",
    "print(b @ b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4faf94-2c9e-4ff4-bc08-ca191bf26f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4bb5a5-5b04-434a-883c-d451a1aef5c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
